{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        283\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9275420336269016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96       844\n",
      "     Opposed       0.88      0.97      0.92       811\n",
      "  Supportive       0.96      0.84      0.90       843\n",
      "\n",
      "    accuracy                           0.93      2498\n",
      "   macro avg       0.93      0.93      0.93      2498\n",
      "weighted avg       0.93      0.93      0.93      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9619695756605284\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       844\n",
      "     Opposed       0.93      1.00      0.96       811\n",
      "  Supportive       1.00      0.89      0.94       843\n",
      "\n",
      "    accuracy                           0.96      2498\n",
      "   macro avg       0.96      0.96      0.96      2498\n",
      "weighted avg       0.96      0.96      0.96      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9755804643714971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99       844\n",
      "     Opposed       0.97      0.98      0.97       811\n",
      "  Supportive       0.97      0.96      0.97       843\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "\n",
      "The best traditional ML model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n",
      "Length of augmented_texts: 14742\n",
      "Length of augmented_labels: 14742\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 8s - 32ms/step - accuracy: 0.8423 - loss: 0.5297 - val_accuracy: 0.8535 - val_loss: 0.4846\n",
      "Epoch 2/5\n",
      "246/246 - 6s - 26ms/step - accuracy: 0.8589 - loss: 0.4656 - val_accuracy: 0.8591 - val_loss: 0.4882\n",
      "Epoch 3/5\n",
      "246/246 - 6s - 26ms/step - accuracy: 0.8764 - loss: 0.4273 - val_accuracy: 0.8566 - val_loss: 0.5009\n",
      "Epoch 4/5\n",
      "246/246 - 7s - 27ms/step - accuracy: 0.8839 - loss: 0.4058 - val_accuracy: 0.8596 - val_loss: 0.5282\n",
      "Epoch 5/5\n",
      "246/246 - 6s - 26ms/step - accuracy: 0.8855 - loss: 0.3998 - val_accuracy: 0.8594 - val_loss: 0.5255\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8593591047812817\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.14      0.23       228\n",
      "           1       0.48      0.08      0.14       351\n",
      "           2       0.87      0.99      0.93      3353\n",
      "\n",
      "    accuracy                           0.86      3932\n",
      "   macro avg       0.66      0.40      0.43      3932\n",
      "weighted avg       0.82      0.86      0.81      3932\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 25s - 103ms/step - accuracy: 0.8432 - loss: 0.5470 - val_accuracy: 0.8527 - val_loss: 0.5204\n",
      "Epoch 2/5\n",
      "246/246 - 23s - 93ms/step - accuracy: 0.8456 - loss: 0.5252 - val_accuracy: 0.8530 - val_loss: 0.5048\n",
      "Epoch 3/5\n",
      "246/246 - 23s - 93ms/step - accuracy: 0.8516 - loss: 0.4839 - val_accuracy: 0.8527 - val_loss: 0.4879\n",
      "Epoch 4/5\n",
      "246/246 - 22s - 90ms/step - accuracy: 0.8633 - loss: 0.4561 - val_accuracy: 0.8538 - val_loss: 0.4930\n",
      "Epoch 5/5\n",
      "246/246 - 23s - 92ms/step - accuracy: 0.8731 - loss: 0.4342 - val_accuracy: 0.8530 - val_loss: 0.5016\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.853001017293998\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.07      0.13       228\n",
      "           1       0.35      0.07      0.11       351\n",
      "           2       0.86      0.99      0.92      3353\n",
      "\n",
      "    accuracy                           0.85      3932\n",
      "   macro avg       0.62      0.38      0.39      3932\n",
      "weighted avg       0.80      0.85      0.80      3932\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 42s - 171ms/step - accuracy: 0.8444 - loss: 0.5428 - val_accuracy: 0.8527 - val_loss: 0.5153\n",
      "Epoch 2/5\n",
      "246/246 - 40s - 162ms/step - accuracy: 0.8463 - loss: 0.4999 - val_accuracy: 0.8520 - val_loss: 0.4862\n",
      "Epoch 3/5\n",
      "246/246 - 40s - 164ms/step - accuracy: 0.8584 - loss: 0.4673 - val_accuracy: 0.8538 - val_loss: 0.4845\n",
      "Epoch 4/5\n",
      "246/246 - 41s - 167ms/step - accuracy: 0.8688 - loss: 0.4413 - val_accuracy: 0.8548 - val_loss: 0.5022\n",
      "Epoch 5/5\n",
      "246/246 - 42s - 169ms/step - accuracy: 0.8762 - loss: 0.4250 - val_accuracy: 0.8545 - val_loss: 0.5217\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.854526958290946\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.08      0.14       228\n",
      "           1       0.41      0.08      0.13       351\n",
      "           2       0.86      0.99      0.92      3353\n",
      "\n",
      "    accuracy                           0.85      3932\n",
      "   macro avg       0.65      0.38      0.40      3932\n",
      "weighted avg       0.81      0.85      0.81      3932\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Ensure NLTK stopwords and WordNet lemmatizer are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep only 'reviewText' and 'Stance' columns\n",
    "df = df[['reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where 'reviewText' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# for full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df['reviewText'])\n",
    "\n",
    "# Encode the target labels\n",
    "y = df['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets for traditional ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Naive Bayes\n",
    "nb_y_pred = nb_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test_ml, nb_y_pred)\n",
    "nb_report = classification_report(y_test_ml, nb_y_pred)\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using SVM\n",
    "svm_y_pred = svm_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test_ml, svm_y_pred)\n",
    "svm_report = classification_report(y_test_ml, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test_ml, rf_y_pred)\n",
    "rf_report = classification_report(y_test_ml, rf_y_pred)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "# Initialize the accuracy_scores dictionary for ML models\n",
    "accuracy_scores_ml = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy\n",
    "}\n",
    "\n",
    "best_ml_model = max(accuracy_scores_ml, key=accuracy_scores_ml.get)\n",
    "print(f\"\\nThe best traditional ML model based on accuracy is: {best_ml_model} with accuracy {accuracy_scores_ml[best_ml_model]}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for deep learning models\n",
    "y_encoded = pd.get_dummies(df['Stance']).values\n",
    "\n",
    "# Split the dataset into training and testing sets for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Augmentation using Synonym Replacement\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "def augment_texts(texts, aug, num_augs=1):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        for _ in range(num_augs):\n",
    "            augmented_texts.append(aug.augment(text))\n",
    "    return augmented_texts\n",
    "\n",
    "# Apply augmentation on training data\n",
    "stance_labels = df['Stance'].unique()\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "for stance in stance_labels:\n",
    "    class_texts = df['reviewText'][df['Stance'] == stance].values\n",
    "    augmented_class_texts = augment_texts(class_texts, aug, num_augs=3)\n",
    "    augmented_texts += augmented_class_texts\n",
    "    augmented_labels += [stance] * len(augmented_class_texts)\n",
    "\n",
    "# Debugging statements to check lengths\n",
    "print(f\"Length of augmented_texts: {len(augmented_texts)}\")\n",
    "print(f\"Length of augmented_labels: {len(augmented_labels)}\")\n",
    "\n",
    "# Ensure lengths match before creating DataFrame\n",
    "if len(augmented_texts) == len(augmented_labels):\n",
    "    augmented_df = pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "else:\n",
    "    print(\"Error: Lengths of augmented_texts and augmented_labels do not match\")\n",
    "\n",
    "# Combine original and augmented data\n",
    "df_augmented = pd.concat([df, augmented_df])\n",
    "\n",
    "# Tokenizer and padding for augmented data\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_aug_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_aug_pad = pad_sequences(X_aug_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for augmented data\n",
    "y_aug_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug_pad, y_aug_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(5000, 128, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_aug)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test_aug_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_aug_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_aug)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test_aug_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_aug_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# BiLSTM Model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "bilstm_model.add(SpatialDropout1D(0.2))\n",
    "bilstm_model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "bilstm_model.add(Dense(3, activation='softmax'))\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_aug)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "bilstm_accuracy = accuracy_score(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare the accuracy of all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy,\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model among all based on accuracy\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        283\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9275420336269016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96       844\n",
      "     Opposed       0.88      0.97      0.92       811\n",
      "  Supportive       0.96      0.84      0.90       843\n",
      "\n",
      "    accuracy                           0.93      2498\n",
      "   macro avg       0.93      0.93      0.93      2498\n",
      "weighted avg       0.93      0.93      0.93      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9619695756605284\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       844\n",
      "     Opposed       0.93      1.00      0.96       811\n",
      "  Supportive       1.00      0.89      0.94       843\n",
      "\n",
      "    accuracy                           0.96      2498\n",
      "   macro avg       0.96      0.96      0.96      2498\n",
      "weighted avg       0.96      0.96      0.96      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9755804643714971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99       844\n",
      "     Opposed       0.97      0.98      0.97       811\n",
      "  Supportive       0.97      0.96      0.97       843\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "\n",
      "The best traditional ML model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n",
      "Length of augmented_texts: 14742\n",
      "Length of augmented_labels: 14742\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 12s - 47ms/step - accuracy: 0.8420 - loss: 0.5359 - val_accuracy: 0.8527 - val_loss: 0.4893\n",
      "Epoch 2/5\n",
      "246/246 - 9s - 35ms/step - accuracy: 0.8557 - loss: 0.4717 - val_accuracy: 0.8586 - val_loss: 0.4891\n",
      "Epoch 3/5\n",
      "246/246 - 9s - 35ms/step - accuracy: 0.8741 - loss: 0.4325 - val_accuracy: 0.8550 - val_loss: 0.5086\n",
      "Epoch 4/5\n",
      "246/246 - 9s - 35ms/step - accuracy: 0.8830 - loss: 0.4092 - val_accuracy: 0.8594 - val_loss: 0.5397\n",
      "Epoch 5/5\n",
      "246/246 - 9s - 35ms/step - accuracy: 0.8850 - loss: 0.4011 - val_accuracy: 0.8589 - val_loss: 0.5414\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8588504577822991\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.11      0.19       228\n",
      "           1       0.49      0.09      0.15       351\n",
      "           2       0.87      0.99      0.92      3353\n",
      "\n",
      "    accuracy                           0.86      3932\n",
      "   macro avg       0.71      0.40      0.42      3932\n",
      "weighted avg       0.83      0.86      0.81      3932\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 31s - 126ms/step - accuracy: 0.8436 - loss: 0.5476 - val_accuracy: 0.8527 - val_loss: 0.5194\n",
      "Epoch 2/5\n",
      "246/246 - 32s - 129ms/step - accuracy: 0.8456 - loss: 0.5227 - val_accuracy: 0.8533 - val_loss: 0.5021\n",
      "Epoch 3/5\n",
      "246/246 - 31s - 128ms/step - accuracy: 0.8537 - loss: 0.4816 - val_accuracy: 0.8525 - val_loss: 0.4892\n",
      "Epoch 4/5\n",
      "246/246 - 32s - 128ms/step - accuracy: 0.8636 - loss: 0.4530 - val_accuracy: 0.8555 - val_loss: 0.4924\n",
      "Epoch 5/5\n",
      "246/246 - 31s - 127ms/step - accuracy: 0.8732 - loss: 0.4326 - val_accuracy: 0.8540 - val_loss: 0.5073\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8540183112919634\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.07      0.13       228\n",
      "           1       0.39      0.07      0.12       351\n",
      "           2       0.86      0.99      0.92      3353\n",
      "\n",
      "    accuracy                           0.85      3932\n",
      "   macro avg       0.62      0.38      0.39      3932\n",
      "weighted avg       0.81      0.85      0.80      3932\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 - 60s - 245ms/step - accuracy: 0.8426 - loss: 0.5449 - val_accuracy: 0.8527 - val_loss: 0.5120\n",
      "Epoch 2/5\n",
      "246/246 - 53s - 215ms/step - accuracy: 0.8470 - loss: 0.4977 - val_accuracy: 0.8530 - val_loss: 0.4868\n",
      "Epoch 3/5\n",
      "246/246 - 51s - 208ms/step - accuracy: 0.8585 - loss: 0.4665 - val_accuracy: 0.8573 - val_loss: 0.4880\n",
      "Epoch 4/5\n",
      "246/246 - 54s - 219ms/step - accuracy: 0.8688 - loss: 0.4428 - val_accuracy: 0.8561 - val_loss: 0.5043\n",
      "Epoch 5/5\n",
      "246/246 - 50s - 203ms/step - accuracy: 0.8756 - loss: 0.4273 - val_accuracy: 0.8543 - val_loss: 0.5251\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.8542726347914548\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.06      0.11       228\n",
      "           1       0.41      0.07      0.12       351\n",
      "           2       0.86      0.99      0.92      3353\n",
      "\n",
      "    accuracy                           0.85      3932\n",
      "   macro avg       0.64      0.37      0.39      3932\n",
      "weighted avg       0.81      0.85      0.80      3932\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Ensure NLTK stopwords and WordNet lemmatizer are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep only 'reviewText' and 'Stance' columns\n",
    "df = df[['reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where 'reviewText' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# for full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df['reviewText'])\n",
    "\n",
    "# Encode the target labels\n",
    "y = df['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets for traditional ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Naive Bayes\n",
    "nb_y_pred = nb_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test_ml, nb_y_pred)\n",
    "nb_report = classification_report(y_test_ml, nb_y_pred)\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using SVM\n",
    "svm_y_pred = svm_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test_ml, svm_y_pred)\n",
    "svm_report = classification_report(y_test_ml, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test_ml, rf_y_pred)\n",
    "rf_report = classification_report(y_test_ml, rf_y_pred)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "# Initialize the accuracy_scores dictionary for ML models\n",
    "accuracy_scores_ml = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy\n",
    "}\n",
    "\n",
    "best_ml_model = max(accuracy_scores_ml, key=accuracy_scores_ml.get)\n",
    "print(f\"\\nThe best traditional ML model based on accuracy is: {best_ml_model} with accuracy {accuracy_scores_ml[best_ml_model]}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for deep learning models\n",
    "y_encoded = pd.get_dummies(df['Stance']).values\n",
    "\n",
    "# Split the dataset into training and testing sets for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Augmentation using Synonym Replacement\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "def augment_texts(texts, aug, num_augs=1):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        for _ in range(num_augs):\n",
    "            augmented_texts.append(aug.augment(text))\n",
    "    return augmented_texts\n",
    "\n",
    "# Apply augmentation on training data\n",
    "stance_labels = df['Stance'].unique()\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "for stance in stance_labels:\n",
    "    class_texts = df['reviewText'][df['Stance'] == stance].values\n",
    "    augmented_class_texts = augment_texts(class_texts, aug, num_augs=3)\n",
    "    augmented_texts += augmented_class_texts\n",
    "    augmented_labels += [stance] * len(augmented_class_texts)\n",
    "\n",
    "# Debugging statements to check lengths\n",
    "print(f\"Length of augmented_texts: {len(augmented_texts)}\")\n",
    "print(f\"Length of augmented_labels: {len(augmented_labels)}\")\n",
    "\n",
    "# Ensure lengths match before creating DataFrame\n",
    "if len(augmented_texts) == len(augmented_labels):\n",
    "    augmented_df = pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "else:\n",
    "    print(\"Error: Lengths of augmented_texts and augmented_labels do not match\")\n",
    "\n",
    "# Combine original and augmented data\n",
    "df_augmented = pd.concat([df, augmented_df])\n",
    "\n",
    "# Tokenizer and padding for augmented data\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_aug_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_aug_pad = pad_sequences(X_aug_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for augmented data\n",
    "y_aug_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug_pad, y_aug_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute class weights for deep learning models\n",
    "class_weights = df['Stance'].value_counts(normalize=True).to_dict()\n",
    "total_classes = len(class_weights)\n",
    "class_weights_dict = {i: (1 / class_weights[i]) * (total_classes / len(class_weights)) for i in class_weights}\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(5000, 128, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(len(df['Stance'].unique()), activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2, class_weight=class_weights_dict)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_aug)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test_aug_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_aug_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(len(df['Stance'].unique()), activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2, class_weight=class_weights_dict)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_aug)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test_aug_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_aug_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# BiLSTM Model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "bilstm_model.add(SpatialDropout1D(0.2))\n",
    "bilstm_model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "bilstm_model.add(Dense(len(df['Stance'].unique()), activation='softmax'))\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2, class_weight=class_weights_dict)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_aug)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "bilstm_accuracy = accuracy_score(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare the accuracy of all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy,\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model among all based on accuracy\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        283\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9275420336269016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96       844\n",
      "     Opposed       0.88      0.97      0.92       811\n",
      "  Supportive       0.96      0.84      0.90       843\n",
      "\n",
      "    accuracy                           0.93      2498\n",
      "   macro avg       0.93      0.93      0.93      2498\n",
      "weighted avg       0.93      0.93      0.93      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9619695756605284\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       844\n",
      "     Opposed       0.93      1.00      0.96       811\n",
      "  Supportive       1.00      0.89      0.94       843\n",
      "\n",
      "    accuracy                           0.96      2498\n",
      "   macro avg       0.96      0.96      0.96      2498\n",
      "weighted avg       0.96      0.96      0.96      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9755804643714971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99       844\n",
      "     Opposed       0.97      0.98      0.97       811\n",
      "  Supportive       0.97      0.96      0.97       843\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "\n",
      "The best traditional ML model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n",
      "Length of augmented_texts: 2256\n",
      "Length of augmented_labels: 2256\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 - 8s - 93ms/step - accuracy: 0.7653 - loss: 0.6010 - val_accuracy: 0.8075 - val_loss: 0.4510\n",
      "Epoch 2/5\n",
      "90/90 - 4s - 41ms/step - accuracy: 0.7932 - loss: 0.4237 - val_accuracy: 0.8110 - val_loss: 0.4261\n",
      "Epoch 3/5\n",
      "90/90 - 4s - 40ms/step - accuracy: 0.8264 - loss: 0.3481 - val_accuracy: 0.8131 - val_loss: 0.4394\n",
      "Epoch 4/5\n",
      "90/90 - 4s - 40ms/step - accuracy: 0.8612 - loss: 0.2756 - val_accuracy: 0.8061 - val_loss: 0.4708\n",
      "Epoch 5/5\n",
      "90/90 - 4s - 40ms/step - accuracy: 0.8701 - loss: 0.2316 - val_accuracy: 0.8145 - val_loss: 0.4894\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8145048814504882\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.17      0.26       198\n",
      "           1       0.64      0.88      0.75       380\n",
      "           2       0.93      0.93      0.93       856\n",
      "\n",
      "    accuracy                           0.81      1434\n",
      "   macro avg       0.72      0.66      0.65      1434\n",
      "weighted avg       0.81      0.81      0.79      1434\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 - 20s - 228ms/step - accuracy: 0.7556 - loss: 0.6370 - val_accuracy: 0.7992 - val_loss: 0.5047\n",
      "Epoch 2/5\n",
      "90/90 - 17s - 185ms/step - accuracy: 0.7744 - loss: 0.4930 - val_accuracy: 0.8026 - val_loss: 0.4461\n",
      "Epoch 3/5\n",
      "90/90 - 16s - 176ms/step - accuracy: 0.8030 - loss: 0.4090 - val_accuracy: 0.8040 - val_loss: 0.4480\n",
      "Epoch 4/5\n",
      "90/90 - 16s - 173ms/step - accuracy: 0.8213 - loss: 0.3664 - val_accuracy: 0.7901 - val_loss: 0.4742\n",
      "Epoch 5/5\n",
      "90/90 - 15s - 169ms/step - accuracy: 0.8377 - loss: 0.3329 - val_accuracy: 0.7943 - val_loss: 0.4912\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.794281729428173\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.11      0.18       198\n",
      "           1       0.60      0.88      0.72       380\n",
      "           2       0.93      0.91      0.92       856\n",
      "\n",
      "    accuracy                           0.79      1434\n",
      "   macro avg       0.72      0.63      0.61      1434\n",
      "weighted avg       0.80      0.79      0.76      1434\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 - 35s - 387ms/step - accuracy: 0.7456 - loss: 0.6252 - val_accuracy: 0.7985 - val_loss: 0.5049\n",
      "Epoch 2/5\n",
      "90/90 - 26s - 290ms/step - accuracy: 0.7748 - loss: 0.4788 - val_accuracy: 0.8061 - val_loss: 0.4432\n",
      "Epoch 3/5\n",
      "90/90 - 27s - 302ms/step - accuracy: 0.8033 - loss: 0.3981 - val_accuracy: 0.8020 - val_loss: 0.4568\n",
      "Epoch 4/5\n",
      "90/90 - 27s - 296ms/step - accuracy: 0.8162 - loss: 0.3684 - val_accuracy: 0.7887 - val_loss: 0.4781\n",
      "Epoch 5/5\n",
      "90/90 - 25s - 280ms/step - accuracy: 0.8307 - loss: 0.3402 - val_accuracy: 0.8026 - val_loss: 0.4915\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.802649930264993\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.13       198\n",
      "           1       0.62      0.87      0.72       380\n",
      "           2       0.92      0.94      0.93       856\n",
      "\n",
      "    accuracy                           0.80      1434\n",
      "   macro avg       0.71      0.63      0.60      1434\n",
      "weighted avg       0.80      0.80      0.77      1434\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Ensure NLTK stopwords and WordNet lemmatizer are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep only 'reviewText' and 'Stance' columns\n",
    "df = df[['reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where 'reviewText' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# for full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df['reviewText'])\n",
    "\n",
    "# Encode the target labels\n",
    "y = df['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets for traditional ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Naive Bayes\n",
    "nb_y_pred = nb_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test_ml, nb_y_pred)\n",
    "nb_report = classification_report(y_test_ml, nb_y_pred)\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using SVM\n",
    "svm_y_pred = svm_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test_ml, svm_y_pred)\n",
    "svm_report = classification_report(y_test_ml, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_ml, y_train_ml)\n",
    "\n",
    "# Predict the stances on the test set using Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test_ml)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test_ml, rf_y_pred)\n",
    "rf_report = classification_report(y_test_ml, rf_y_pred)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "# Initialize the accuracy_scores dictionary for ML models\n",
    "accuracy_scores_ml = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy\n",
    "}\n",
    "\n",
    "best_ml_model = max(accuracy_scores_ml, key=accuracy_scores_ml.get)\n",
    "print(f\"\\nThe best traditional ML model based on accuracy is: {best_ml_model} with accuracy {accuracy_scores_ml[best_ml_model]}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for deep learning models\n",
    "y_encoded = pd.get_dummies(df['Stance']).values\n",
    "\n",
    "# Split the dataset into training and testing sets for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Augmentation using Synonym Replacement\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "def augment_texts(texts, aug, num_augs=1):\n",
    "    augmented_texts = []\n",
    "    for text in texts:\n",
    "        for _ in range(num_augs):\n",
    "            augmented_texts.append(aug.augment(text))\n",
    "    return augmented_texts\n",
    "\n",
    "# Define a threshold for what constitutes a minority class\n",
    "threshold = 500  # Example threshold; adjust based on your needs\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = df['Stance'].value_counts()\n",
    "\n",
    "# Identify minority classes\n",
    "minority_classes = class_counts[class_counts < threshold].index\n",
    "\n",
    "# Apply augmentation on minority classes only\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "for stance in minority_classes:\n",
    "    class_texts = df['reviewText'][df['Stance'] == stance].values\n",
    "    augmented_class_texts = augment_texts(class_texts, aug, num_augs=3)\n",
    "    augmented_texts += augmented_class_texts\n",
    "    augmented_labels += [stance] * len(augmented_class_texts)\n",
    "\n",
    "# Debugging statements to check lengths\n",
    "print(f\"Length of augmented_texts: {len(augmented_texts)}\")\n",
    "print(f\"Length of augmented_labels: {len(augmented_labels)}\")\n",
    "\n",
    "# Ensure lengths match before creating DataFrame\n",
    "if len(augmented_texts) == len(augmented_labels):\n",
    "    augmented_df = pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "else:\n",
    "    print(\"Error: Lengths of augmented_texts and augmented_labels do not match\")\n",
    "\n",
    "# Combine original and augmented data\n",
    "df_augmented = pd.concat([df, augmented_df])\n",
    "\n",
    "# Tokenizer and padding for augmented data\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_aug_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_aug_pad = pad_sequences(X_aug_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for augmented data\n",
    "y_aug_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug_pad, y_aug_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(5000, 128, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_aug)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test_aug_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_aug_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_aug)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test_aug_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_aug_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# BiLSTM Model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "bilstm_model.add(SpatialDropout1D(0.2))\n",
    "bilstm_model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "bilstm_model.add(Dense(3, activation='softmax'))\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_aug, y_train_aug, epochs=5, batch_size=64, validation_data=(X_test_aug, y_test_aug), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_aug)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "y_test_aug_labels = y_test_aug.argmax(axis=1)\n",
    "\n",
    "bilstm_accuracy = accuracy_score(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_aug_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare the accuracy of all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy,\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model among all based on accuracy\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "Accuracy: 0.9275420336269016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.88      0.97      0.92       811\n",
      "           2       0.96      0.84      0.90       843\n",
      "\n",
      "    accuracy                           0.93      2498\n",
      "   macro avg       0.93      0.93      0.93      2498\n",
      "weighted avg       0.93      0.93      0.93      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9619695756605284\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       844\n",
      "           1       0.93      1.00      0.96       811\n",
      "           2       1.00      0.89      0.94       843\n",
      "\n",
      "    accuracy                           0.96      2498\n",
      "   macro avg       0.96      0.96      0.96      2498\n",
      "weighted avg       0.96      0.96      0.96      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9755804643714971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       844\n",
      "           1       0.97      0.98      0.97       811\n",
      "           2       0.97      0.96      0.97       843\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 5s - 32ms/step - accuracy: 0.5364 - loss: 0.9226 - val_accuracy: 0.6333 - val_loss: 0.7501\n",
      "Epoch 2/5\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.7448 - loss: 0.5799 - val_accuracy: 0.6601 - val_loss: 0.7115\n",
      "Epoch 3/5\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.8709 - loss: 0.3397 - val_accuracy: 0.6401 - val_loss: 0.9023\n",
      "Epoch 4/5\n",
      "157/157 - 4s - 24ms/step - accuracy: 0.9479 - loss: 0.1731 - val_accuracy: 0.6293 - val_loss: 1.0596\n",
      "Epoch 5/5\n",
      "157/157 - 4s - 26ms/step - accuracy: 0.9784 - loss: 0.0850 - val_accuracy: 0.6281 - val_loss: 1.1702\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.6281024819855885\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.75      0.63       844\n",
      "           1       0.56      0.50      0.53       811\n",
      "           2       0.85      0.63      0.72       843\n",
      "\n",
      "    accuracy                           0.63      2498\n",
      "   macro avg       0.65      0.63      0.63      2498\n",
      "weighted avg       0.66      0.63      0.63      2498\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 14s - 86ms/step - accuracy: 0.5133 - loss: 0.9714 - val_accuracy: 0.5761 - val_loss: 0.8896\n",
      "Epoch 2/5\n",
      "157/157 - 11s - 68ms/step - accuracy: 0.6133 - loss: 0.8297 - val_accuracy: 0.5813 - val_loss: 0.8837\n",
      "Epoch 3/5\n",
      "157/157 - 11s - 68ms/step - accuracy: 0.6746 - loss: 0.7363 - val_accuracy: 0.5913 - val_loss: 0.9029\n",
      "Epoch 4/5\n",
      "157/157 - 11s - 67ms/step - accuracy: 0.7201 - loss: 0.6472 - val_accuracy: 0.5965 - val_loss: 0.9242\n",
      "Epoch 5/5\n",
      "157/157 - 11s - 67ms/step - accuracy: 0.7609 - loss: 0.5646 - val_accuracy: 0.5833 - val_loss: 1.0020\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.5832666132906325\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.55       844\n",
      "           1       0.53      0.50      0.51       811\n",
      "           2       0.63      0.74      0.68       843\n",
      "\n",
      "    accuracy                           0.58      2498\n",
      "   macro avg       0.58      0.58      0.58      2498\n",
      "weighted avg       0.58      0.58      0.58      2498\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 23s - 148ms/step - accuracy: 0.4991 - loss: 0.9848 - val_accuracy: 0.5725 - val_loss: 0.8873\n",
      "Epoch 2/5\n",
      "157/157 - 32s - 206ms/step - accuracy: 0.6093 - loss: 0.8334 - val_accuracy: 0.5889 - val_loss: 0.8823\n",
      "Epoch 3/5\n",
      "157/157 - 32s - 207ms/step - accuracy: 0.6704 - loss: 0.7438 - val_accuracy: 0.5913 - val_loss: 0.8941\n",
      "Epoch 4/5\n",
      "157/157 - 34s - 216ms/step - accuracy: 0.7142 - loss: 0.6568 - val_accuracy: 0.5821 - val_loss: 0.9192\n",
      "Epoch 5/5\n",
      "157/157 - 32s - 206ms/step - accuracy: 0.7536 - loss: 0.5831 - val_accuracy: 0.5881 - val_loss: 0.9718\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.588070456365092\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55       844\n",
      "           1       0.53      0.52      0.52       811\n",
      "           2       0.66      0.70      0.68       843\n",
      "\n",
      "    accuracy                           0.59      2498\n",
      "   macro avg       0.59      0.59      0.59      2498\n",
      "weighted avg       0.59      0.59      0.59      2498\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure NLTK stopwords and WordNet lemmatizer are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep only 'reviewText' and 'Stance' columns\n",
    "df = df[['reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where 'reviewText' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df['reviewText'])\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Stance'])\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets for traditional ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_ml, y_train_ml)\n",
    "nb_y_pred = nb_model.predict(X_test_ml)\n",
    "nb_accuracy = accuracy_score(y_test_ml, nb_y_pred)\n",
    "nb_report = classification_report(y_test_ml, nb_y_pred)\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_ml, y_train_ml)\n",
    "svm_y_pred = svm_model.predict(X_test_ml)\n",
    "svm_accuracy = accuracy_score(y_test_ml, svm_y_pred)\n",
    "svm_report = classification_report(y_test_ml, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_ml, y_train_ml)\n",
    "rf_y_pred = rf_model.predict(X_test_ml)\n",
    "rf_accuracy = accuracy_score(y_test_ml, rf_y_pred)\n",
    "rf_report = classification_report(y_test_ml, rf_y_pred)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Apply SMOTE to text data\n",
    "X_smote_dl, y_smote_dl = smote.fit_resample(X_pad, y)\n",
    "\n",
    "# Split the balanced dataset into training and testing sets for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_smote_dl, y_smote_dl, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train_dl and y_test_dl to categorical\n",
    "y_train_dl = to_categorical(y_train_dl, num_classes=len(label_encoder.classes_))\n",
    "y_test_dl = to_categorical(y_test_dl, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(5000, 128, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "cnn_y_pred = cnn_model.predict(X_test_dl)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_dl.argmax(axis=1), cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_dl.argmax(axis=1), cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "lstm_y_pred = lstm_model.predict(X_test_dl)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "lstm_accuracy = accuracy_score(y_test_dl.argmax(axis=1), lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_dl.argmax(axis=1), lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# BiLSTM Model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "bilstm_model.add(SpatialDropout1D(0.2))\n",
    "bilstm_model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "bilstm_model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_dl)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "bilstm_accuracy = accuracy_score(y_test_dl.argmax(axis=1), bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_dl.argmax(axis=1), bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare the accuracy of all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy,\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model among all based on accuracy\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        283\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "Accuracy: 0.9275420336269016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.95      0.97      0.96       844\n",
      "     Opposed       0.88      0.97      0.92       811\n",
      "  Supportive       0.96      0.84      0.90       843\n",
      "\n",
      "    accuracy                           0.93      2498\n",
      "   macro avg       0.93      0.93      0.93      2498\n",
      "weighted avg       0.93      0.93      0.93      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9619695756605284\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       844\n",
      "     Opposed       0.93      1.00      0.96       811\n",
      "  Supportive       1.00      0.89      0.94       843\n",
      "\n",
      "    accuracy                           0.96      2498\n",
      "   macro avg       0.96      0.96      0.96      2498\n",
      "weighted avg       0.96      0.96      0.96      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9755804643714971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.98      1.00      0.99       844\n",
      "     Opposed       0.97      0.98      0.97       811\n",
      "  Supportive       0.97      0.96      0.97       843\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 3s - 47ms/step - accuracy: 0.8151 - loss: 0.5776 - val_accuracy: 0.8464 - val_loss: 0.4419\n",
      "Epoch 2/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.8547 - loss: 0.3570 - val_accuracy: 0.8637 - val_loss: 0.3464\n",
      "Epoch 3/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.9252 - loss: 0.2140 - val_accuracy: 0.8759 - val_loss: 0.3640\n",
      "Epoch 4/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.9753 - loss: 0.0856 - val_accuracy: 0.8647 - val_loss: 0.5296\n",
      "Epoch 5/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.9954 - loss: 0.0246 - val_accuracy: 0.8779 - val_loss: 0.5031\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8779247202441506\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.40      0.49        52\n",
      "           1       0.65      0.32      0.43        99\n",
      "           2       0.90      0.97      0.93       832\n",
      "\n",
      "    accuracy                           0.88       983\n",
      "   macro avg       0.73      0.57      0.62       983\n",
      "weighted avg       0.86      0.88      0.86       983\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 9s - 142ms/step - accuracy: 0.8359 - loss: 0.5898 - val_accuracy: 0.8464 - val_loss: 0.5009\n",
      "Epoch 2/5\n",
      "62/62 - 7s - 107ms/step - accuracy: 0.8499 - loss: 0.4621 - val_accuracy: 0.8535 - val_loss: 0.4187\n",
      "Epoch 3/5\n",
      "62/62 - 7s - 109ms/step - accuracy: 0.8748 - loss: 0.3198 - val_accuracy: 0.8708 - val_loss: 0.3763\n",
      "Epoch 4/5\n",
      "62/62 - 7s - 108ms/step - accuracy: 0.9247 - loss: 0.2205 - val_accuracy: 0.8850 - val_loss: 0.3617\n",
      "Epoch 5/5\n",
      "62/62 - 7s - 107ms/step - accuracy: 0.9524 - loss: 0.1477 - val_accuracy: 0.8810 - val_loss: 0.4630\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8809766022380467\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.46      0.55        52\n",
      "           1       0.63      0.27      0.38        99\n",
      "           2       0.90      0.98      0.94       832\n",
      "\n",
      "    accuracy                           0.88       983\n",
      "   macro avg       0.74      0.57      0.62       983\n",
      "weighted avg       0.86      0.88      0.86       983\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 15s - 250ms/step - accuracy: 0.8377 - loss: 0.5648 - val_accuracy: 0.8464 - val_loss: 0.4807\n",
      "Epoch 2/5\n",
      "62/62 - 12s - 193ms/step - accuracy: 0.8525 - loss: 0.4007 - val_accuracy: 0.8535 - val_loss: 0.3555\n",
      "Epoch 3/5\n",
      "62/62 - 12s - 193ms/step - accuracy: 0.8850 - loss: 0.2799 - val_accuracy: 0.8678 - val_loss: 0.4038\n",
      "Epoch 4/5\n",
      "62/62 - 12s - 195ms/step - accuracy: 0.9199 - loss: 0.2160 - val_accuracy: 0.8830 - val_loss: 0.4051\n",
      "Epoch 5/5\n",
      "62/62 - 12s - 191ms/step - accuracy: 0.9425 - loss: 0.1622 - val_accuracy: 0.8810 - val_loss: 0.4393\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.8809766022380467\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.46      0.54        52\n",
      "           1       0.59      0.36      0.45        99\n",
      "           2       0.91      0.97      0.94       832\n",
      "\n",
      "    accuracy                           0.88       983\n",
      "   macro avg       0.72      0.60      0.64       983\n",
      "weighted avg       0.86      0.88      0.87       983\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9755804643714971\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install googletrans==4.0.0-rc1 pandas scikit-learn tensorflow imbalanced-learn nlpaug\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "from googletrans import Translator\n",
    "\n",
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep only 'reviewText' and 'Stance' columns\n",
    "df = df[['reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where 'reviewText' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# For full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure NLTK stopwords and WordNet lemmatizer are downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Define back-translation function\n",
    "def back_translate(text, src_language='en', mid_language='fr'):\n",
    "    try:\n",
    "        translated_text = translator.translate(text, src=src_language, dest=mid_language).text\n",
    "        back_translated_text = translator.translate(translated_text, src=mid_language, dest=src_language).text\n",
    "        return back_translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during back-translation: {e}\")\n",
    "        return text\n",
    "\n",
    "# Define function to augment minority class\n",
    "def augment_minority_class(df, class_label, src_language='en', mid_language='fr'):\n",
    "    minority_texts = df[df['Stance'] == class_label]['reviewText'].tolist()\n",
    "    augmented_texts = [back_translate(text, src_language, mid_language) for text in minority_texts]\n",
    "    augmented_labels = [class_label] * len(augmented_texts)\n",
    "    return pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "\n",
    "# Define threshold for minority class\n",
    "threshold = 100  # Adjust based on your needs\n",
    "\n",
    "# Identify minority classes\n",
    "class_counts = df['Stance'].value_counts()\n",
    "minority_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "\n",
    "# Apply back-translation for all minority classes\n",
    "augmented_df_list = [augment_minority_class(df, cls) for cls in minority_classes]\n",
    "df_augmented = pd.concat([df] + augmented_df_list, ignore_index=True)\n",
    "\n",
    "# Text Vectorization for ML models\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df_augmented['reviewText'])\n",
    "y = df_augmented['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split dataset for ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate ML models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    accuracy = accuracy_score(y_test_ml, y_pred)\n",
    "    report = classification_report(y_test_ml, y_pred)\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "y_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split dataset for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train CNN model\n",
    "cnn_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_dl)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_dl_labels = y_test_dl.argmax(axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_dl_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_dl_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# Define and train LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_dl)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "lstm_accuracy = accuracy_score(y_test_dl_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_dl_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# Define and train BiLSTM model\n",
    "bilstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_dl)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "bilstm_accuracy = accuracy_score(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': accuracy_score(y_test_ml, models['Naive Bayes'].predict(X_test_ml)),\n",
    "    'SVM': accuracy_score(y_test_ml, models['SVM'].predict(X_test_ml)),\n",
    "    'Random Forest': accuracy_score(y_test_ml, models['Random Forest'].predict(X_test_ml)),\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        282\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9187349879903923\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.98      0.97       826\n",
      "     Opposed       0.84      0.97      0.90       816\n",
      "  Supportive       0.97      0.82      0.89       856\n",
      "\n",
      "    accuracy                           0.92      2498\n",
      "   macro avg       0.92      0.92      0.92      2498\n",
      "weighted avg       0.93      0.92      0.92      2498\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.9655724579663731\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       826\n",
      "     Opposed       0.94      1.00      0.97       816\n",
      "  Supportive       1.00      0.90      0.95       856\n",
      "\n",
      "    accuracy                           0.97      2498\n",
      "   macro avg       0.97      0.97      0.97      2498\n",
      "weighted avg       0.97      0.97      0.97      2498\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9795836669335468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       1.00      1.00      1.00       826\n",
      "     Opposed       0.97      0.97      0.97       816\n",
      "  Supportive       0.97      0.97      0.97       856\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 3s - 43ms/step - accuracy: 0.8494 - loss: 0.5253 - val_accuracy: 0.8383 - val_loss: 0.4297\n",
      "Epoch 2/5\n",
      "62/62 - 1s - 24ms/step - accuracy: 0.8616 - loss: 0.3376 - val_accuracy: 0.8515 - val_loss: 0.3602\n",
      "Epoch 3/5\n",
      "62/62 - 1s - 24ms/step - accuracy: 0.9356 - loss: 0.1903 - val_accuracy: 0.8637 - val_loss: 0.3906\n",
      "Epoch 4/5\n",
      "62/62 - 1s - 24ms/step - accuracy: 0.9776 - loss: 0.0726 - val_accuracy: 0.8606 - val_loss: 0.4719\n",
      "Epoch 5/5\n",
      "62/62 - 2s - 25ms/step - accuracy: 0.9964 - loss: 0.0193 - val_accuracy: 0.8576 - val_loss: 0.5761\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000013308713740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8575788402848423\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.37      0.44        57\n",
      "           1       0.55      0.27      0.37       102\n",
      "           2       0.89      0.96      0.92       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.66      0.54      0.58       983\n",
      "weighted avg       0.83      0.86      0.84       983\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 6s - 101ms/step - accuracy: 0.8379 - loss: 0.5935 - val_accuracy: 0.8383 - val_loss: 0.5231\n",
      "Epoch 2/5\n",
      "62/62 - 4s - 68ms/step - accuracy: 0.8517 - loss: 0.4606 - val_accuracy: 0.8403 - val_loss: 0.4426\n",
      "Epoch 3/5\n",
      "62/62 - 4s - 67ms/step - accuracy: 0.8746 - loss: 0.3288 - val_accuracy: 0.8484 - val_loss: 0.3870\n",
      "Epoch 4/5\n",
      "62/62 - 4s - 66ms/step - accuracy: 0.9137 - loss: 0.2352 - val_accuracy: 0.8433 - val_loss: 0.4248\n",
      "Epoch 5/5\n",
      "62/62 - 4s - 71ms/step - accuracy: 0.9397 - loss: 0.1665 - val_accuracy: 0.8515 - val_loss: 0.4738\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8514750762970499\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.37      0.44        57\n",
      "           1       0.48      0.27      0.35       102\n",
      "           2       0.89      0.96      0.92       824\n",
      "\n",
      "    accuracy                           0.85       983\n",
      "   macro avg       0.64      0.53      0.57       983\n",
      "weighted avg       0.83      0.85      0.83       983\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 10s - 166ms/step - accuracy: 0.8382 - loss: 0.5494 - val_accuracy: 0.8383 - val_loss: 0.5012\n",
      "Epoch 2/5\n",
      "62/62 - 7s - 113ms/step - accuracy: 0.8578 - loss: 0.3941 - val_accuracy: 0.8454 - val_loss: 0.3877\n",
      "Epoch 3/5\n",
      "62/62 - 8s - 136ms/step - accuracy: 0.8896 - loss: 0.2748 - val_accuracy: 0.8566 - val_loss: 0.4145\n",
      "Epoch 4/5\n",
      "62/62 - 8s - 132ms/step - accuracy: 0.9232 - loss: 0.2036 - val_accuracy: 0.8576 - val_loss: 0.4419\n",
      "Epoch 5/5\n",
      "62/62 - 7s - 116ms/step - accuracy: 0.9458 - loss: 0.1483 - val_accuracy: 0.8474 - val_loss: 0.4383\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.8474059003051883\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.35      0.40        57\n",
      "           1       0.47      0.37      0.42       102\n",
      "           2       0.90      0.94      0.92       824\n",
      "\n",
      "    accuracy                           0.85       983\n",
      "   macro avg       0.62      0.55      0.58       983\n",
      "weighted avg       0.83      0.85      0.84       983\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9795836669335468\n",
      "Similarity Score between 53rdcard and Aaron: 0.025672492209915476\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "from googletrans import Translator \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Load NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load the original dataset\n",
    "df_original = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep 'reviewerName', 'reviewText', and 'Stance' columns\n",
    "df = df_original[['reviewerName', 'reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where any of the required columns are NaN\n",
    "df = df.dropna(subset=['reviewerName', 'reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# For full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Define back-translation function\n",
    "def back_translate(text, src_language='en', mid_language='fr'):\n",
    "    try:\n",
    "        translated_text = translator.translate(text, src=src_language, dest=mid_language).text\n",
    "        back_translated_text = translator.translate(translated_text, src=mid_language, dest=src_language).text\n",
    "        return back_translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during back-translation: {e}\")\n",
    "        return text\n",
    "\n",
    "# Define function to augment minority class\n",
    "def augment_minority_class(df, class_label, src_language='en', mid_language='fr'):\n",
    "    minority_texts = df[df['Stance'] == class_label]['reviewText'].tolist()\n",
    "    augmented_texts = [back_translate(text, src_language, mid_language) for text in minority_texts]\n",
    "    augmented_labels = [class_label] * len(augmented_texts)\n",
    "    return pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "\n",
    "# Define threshold for minority class\n",
    "threshold = 100  # Adjust based on your needs\n",
    "\n",
    "# Identify minority classes\n",
    "class_counts = df['Stance'].value_counts()\n",
    "minority_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "\n",
    "# Apply back-translation for all minority classes\n",
    "augmented_df_list = [augment_minority_class(df, cls) for cls in minority_classes]\n",
    "df_augmented = pd.concat([df] + augmented_df_list, ignore_index=True)\n",
    "\n",
    "# Text Vectorization for ML models\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df_augmented['reviewText'])\n",
    "y = df_augmented['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split dataset for ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate ML models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    accuracy = accuracy_score(y_test_ml, y_pred)\n",
    "    report = classification_report(y_test_ml, y_pred)\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "y_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split dataset for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train CNN model\n",
    "cnn_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_dl)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_dl_labels = y_test_dl.argmax(axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_dl_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_dl_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# Define and train LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_dl)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "lstm_accuracy = accuracy_score(y_test_dl_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_dl_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# Define and train BiLSTM model\n",
    "bilstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_dl)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "bilstm_accuracy = accuracy_score(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': accuracy_score(y_test_ml, models['Naive Bayes'].predict(X_test_ml)),\n",
    "    'SVM': accuracy_score(y_test_ml, models['SVM'].predict(X_test_ml)),\n",
    "    'Random Forest': accuracy_score(y_test_ml, models['Random Forest'].predict(X_test_ml)),\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n",
    "\n",
    "# # Calculate similarity between two users\n",
    "# def get_user_reviews(df, user_name):\n",
    "#     \"\"\"Extract reviews for a specific user.\"\"\"\n",
    "#     return df[df['reviewerName'] == user_name]['reviewText'].tolist()\n",
    "\n",
    "# def compute_similarity(user1_reviews, user2_reviews, vectorizer):\n",
    "#     \"\"\"Compute cosine similarity between reviews of two users.\"\"\"\n",
    "#     # Combine reviews from both users\n",
    "#     combined_reviews = user1_reviews + user2_reviews\n",
    "    \n",
    "#     # Transform reviews to TF-IDF vectors\n",
    "#     vectors = vectorizer.transform(combined_reviews)\n",
    "    \n",
    "#     # Compute cosine similarity between user 1 and user 2\n",
    "#     similarity_matrix = cosine_similarity(vectors[:len(user1_reviews)], vectors[len(user1_reviews):])\n",
    "    \n",
    "#     # Return the average similarity score\n",
    "#     return similarity_matrix.mean()\n",
    "\n",
    "# # Define your users\n",
    "# user1 = '53rdcard'\n",
    "# user2 = 'Aaron'\n",
    "\n",
    "# # Get reviews for each user\n",
    "# user1_reviews = get_user_reviews(df, user1)\n",
    "# user2_reviews = get_user_reviews(df, user2)\n",
    "\n",
    "# # Vectorize the reviews using the same TF-IDF vectorizer as before\n",
    "# tfidf = TfidfVectorizer(max_df=0.7)\n",
    "# tfidf.fit(df['reviewText'])  # Fit on all reviews in the dataset\n",
    "\n",
    "# # Compute similarity score\n",
    "# similarity_score = compute_similarity(user1_reviews, user2_reviews, tfidf)\n",
    "# print(f\"Similarity Score between {user1} and {user2}: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score between 53rdcard and Aaron: 0.025672492209915476\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Load NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the original dataset\n",
    "df_original = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep 'reviewerName' and 'reviewText' columns\n",
    "df = df_original[['reviewerName', 'reviewText']]\n",
    "\n",
    "# Drop rows where any of the required columns are NaN\n",
    "df = df.dropna(subset=['reviewerName', 'reviewText'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# For full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Function to get user reviews\n",
    "def get_user_reviews(df, user_name):\n",
    "    \"\"\"Extract reviews for a specific user.\"\"\"\n",
    "    return df[df['reviewerName'] == user_name]['reviewText'].tolist()\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(user1_reviews, user2_reviews, vectorizer):\n",
    "    \"\"\"Compute cosine similarity between reviews of two users.\"\"\"\n",
    "    # Combine reviews from both users\n",
    "    combined_reviews = user1_reviews + user2_reviews\n",
    "    \n",
    "    # Transform reviews to TF-IDF vectors\n",
    "    vectors = vectorizer.transform(combined_reviews)\n",
    "    \n",
    "    # Compute cosine similarity between user 1 and user 2\n",
    "    similarity_matrix = cosine_similarity(vectors[:len(user1_reviews)], vectors[len(user1_reviews):])\n",
    "    \n",
    "    # Return the average similarity score\n",
    "    return similarity_matrix.mean()\n",
    "\n",
    "# Define your users\n",
    "user1 = '53rdcard'\n",
    "user2 = 'Aaron'\n",
    "\n",
    "# Get reviews for each user\n",
    "user1_reviews = get_user_reviews(df, user1)\n",
    "user2_reviews = get_user_reviews(df, user2)\n",
    "\n",
    "# Vectorize the reviews using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "tfidf.fit(df['reviewText'])  # Fit on all reviews in the dataset\n",
    "\n",
    "# Compute similarity score\n",
    "similarity_score = compute_similarity(user1_reviews, user2_reviews, tfidf)\n",
    "print(f\"Similarity Score between {user1} and {user2}: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        282\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9187349879903923\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.98      0.97       826\n",
      "     Opposed       0.84      0.97      0.90       816\n",
      "  Supportive       0.97      0.82      0.89       856\n",
      "\n",
      "    accuracy                           0.92      2498\n",
      "   macro avg       0.92      0.92      0.92      2498\n",
      "weighted avg       0.93      0.92      0.92      2498\n",
      "\n",
      "Trust-Based Accuracy for Naive Bayes: 0.998661311914324\n",
      "SVM Results:\n",
      "Accuracy: 0.9655724579663731\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       826\n",
      "     Opposed       0.94      1.00      0.97       816\n",
      "  Supportive       1.00      0.90      0.95       856\n",
      "\n",
      "    accuracy                           0.97      2498\n",
      "   macro avg       0.97      0.97      0.97      2498\n",
      "weighted avg       0.97      0.97      0.97      2498\n",
      "\n",
      "Trust-Based Accuracy for SVM: 0.9779501837484688\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9795836669335468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       1.00      1.00      1.00       826\n",
      "     Opposed       0.97      0.97      0.97       816\n",
      "  Supportive       0.97      0.97      0.97       856\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "Trust-Based Accuracy for Random Forest: 1.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 3s - 45ms/step - accuracy: 0.8377 - loss: 0.5426 - val_accuracy: 0.8383 - val_loss: 0.4392\n",
      "Epoch 2/5\n",
      "62/62 - 2s - 26ms/step - accuracy: 0.8550 - loss: 0.3507 - val_accuracy: 0.8494 - val_loss: 0.3672\n",
      "Epoch 3/5\n",
      "62/62 - 2s - 26ms/step - accuracy: 0.9313 - loss: 0.2035 - val_accuracy: 0.8688 - val_loss: 0.4090\n",
      "Epoch 4/5\n",
      "62/62 - 2s - 29ms/step - accuracy: 0.9804 - loss: 0.0724 - val_accuracy: 0.8698 - val_loss: 0.4781\n",
      "Epoch 5/5\n",
      "62/62 - 2s - 25ms/step - accuracy: 0.9969 - loss: 0.0181 - val_accuracy: 0.8616 - val_loss: 0.5870\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.861648016276704\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.39      0.46        57\n",
      "           1       0.60      0.26      0.37       102\n",
      "           2       0.89      0.97      0.93       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.68      0.54      0.58       983\n",
      "weighted avg       0.84      0.86      0.84       983\n",
      "\n",
      "Trust-Based Accuracy for CNN: 0.8965896589658966\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 8s - 125ms/step - accuracy: 0.8412 - loss: 0.5849 - val_accuracy: 0.8383 - val_loss: 0.5243\n",
      "Epoch 2/5\n",
      "62/62 - 6s - 96ms/step - accuracy: 0.8527 - loss: 0.4485 - val_accuracy: 0.8383 - val_loss: 0.4274\n",
      "Epoch 3/5\n",
      "62/62 - 6s - 90ms/step - accuracy: 0.8756 - loss: 0.3128 - val_accuracy: 0.8535 - val_loss: 0.3967\n",
      "Epoch 4/5\n",
      "62/62 - 6s - 90ms/step - accuracy: 0.9183 - loss: 0.2240 - val_accuracy: 0.8616 - val_loss: 0.4052\n",
      "Epoch 5/5\n",
      "62/62 - 6s - 90ms/step - accuracy: 0.9489 - loss: 0.1511 - val_accuracy: 0.8596 - val_loss: 0.5094\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8596134282807731\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.35      0.44        57\n",
      "           1       0.53      0.25      0.34       102\n",
      "           2       0.89      0.97      0.93       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.67      0.53      0.57       983\n",
      "weighted avg       0.83      0.86      0.84       983\n",
      "\n",
      "Trust-Based Accuracy for LSTM: 0.9022118742724098\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 14s - 219ms/step - accuracy: 0.8486 - loss: 0.5585 - val_accuracy: 0.8383 - val_loss: 0.4984\n",
      "Epoch 2/5\n",
      "62/62 - 10s - 158ms/step - accuracy: 0.8542 - loss: 0.3851 - val_accuracy: 0.8444 - val_loss: 0.3998\n",
      "Epoch 3/5\n",
      "62/62 - 10s - 157ms/step - accuracy: 0.8873 - loss: 0.2791 - val_accuracy: 0.8505 - val_loss: 0.4008\n",
      "Epoch 4/5\n",
      "62/62 - 10s - 164ms/step - accuracy: 0.9120 - loss: 0.2159 - val_accuracy: 0.8545 - val_loss: 0.4435\n",
      "Epoch 5/5\n",
      "62/62 - 10s - 155ms/step - accuracy: 0.9405 - loss: 0.1639 - val_accuracy: 0.8606 - val_loss: 0.5533\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.8606307222787386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.26      0.40        57\n",
      "           1       0.51      0.27      0.36       102\n",
      "           2       0.88      0.97      0.93       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.74      0.50      0.56       983\n",
      "weighted avg       0.84      0.86      0.84       983\n",
      "\n",
      "Trust-Based Accuracy for BiLSTM: 0.8966704936854191\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.9795836669335468\n",
      "\n",
      "The best model based on trust-based accuracy is: Random Forest with trust-based accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "from googletrans import Translator \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Load NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load the original dataset\n",
    "df_original = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep 'reviewerName', 'reviewText', and 'Stance' columns\n",
    "df = df_original[['reviewerName', 'reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where any of the required columns are NaN\n",
    "df = df.dropna(subset=['reviewerName', 'reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# For full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Define back-translation function\n",
    "def back_translate(text, src_language='en', mid_language='fr'):\n",
    "    try:\n",
    "        translated_text = translator.translate(text, src=src_language, dest=mid_language).text\n",
    "        back_translated_text = translator.translate(translated_text, src=mid_language, dest=src_language).text\n",
    "        return back_translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during back-translation: {e}\")\n",
    "        return text\n",
    "\n",
    "# Define function to augment minority class\n",
    "def augment_minority_class(df, class_label, src_language='en', mid_language='fr'):\n",
    "    minority_texts = df[df['Stance'] == class_label]['reviewText'].tolist()\n",
    "    augmented_texts = [back_translate(text, src_language, mid_language) for text in minority_texts]\n",
    "    augmented_labels = [class_label] * len(augmented_texts)\n",
    "    return pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "\n",
    "# Define threshold for minority class\n",
    "threshold = 100  # Adjust based on your needs\n",
    "\n",
    "# Identify minority classes\n",
    "class_counts = df['Stance'].value_counts()\n",
    "minority_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "\n",
    "# Apply back-translation for all minority classes\n",
    "augmented_df_list = [augment_minority_class(df, cls) for cls in minority_classes]\n",
    "df_augmented = pd.concat([df] + augmented_df_list, ignore_index=True)\n",
    "\n",
    "# Text Vectorization for ML models\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df_augmented['reviewText'])\n",
    "y = df_augmented['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split dataset for ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate ML models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(kernel='linear', probability=True),  # Set probability=True for SVM\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Confidence threshold\n",
    "confidence_threshold = 0.8\n",
    "\n",
    "def trust_based_accuracy(y_true, y_pred, confidence_scores, threshold):\n",
    "    mask = confidence_scores >= threshold\n",
    "    y_true_trust = y_true[mask]\n",
    "    y_pred_trust = y_pred[mask]\n",
    "    if len(y_true_trust) == 0:\n",
    "        return None  # No predictions above the threshold\n",
    "    return accuracy_score(y_true_trust, y_pred_trust)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    y_probs = model.predict_proba(X_test_ml)\n",
    "    confidence_scores = y_probs.max(axis=1)\n",
    "    \n",
    "    # Calculate standard accuracy\n",
    "    accuracy = accuracy_score(y_test_ml, y_pred)\n",
    "    report = classification_report(y_test_ml, y_pred)\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Calculate trust-based accuracy\n",
    "    trust_accuracy = trust_based_accuracy(y_test_ml, y_pred, confidence_scores, confidence_threshold)\n",
    "    if trust_accuracy is not None:\n",
    "        print(f\"Trust-Based Accuracy for {name}: {trust_accuracy}\")\n",
    "    else:\n",
    "        print(f\"No predictions above the confidence threshold for {name}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "y_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split dataset for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train CNN model\n",
    "cnn_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_dl)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_dl_labels = y_test_dl.argmax(axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_dl_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_dl_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# Calculate confidence scores for CNN\n",
    "cnn_confidence_scores = cnn_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for CNN\n",
    "cnn_trust_accuracy = trust_based_accuracy(y_test_dl_labels, cnn_y_pred_labels, cnn_confidence_scores, confidence_threshold)\n",
    "if cnn_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for CNN: {cnn_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for CNN\")\n",
    "\n",
    "# Define and train LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_dl)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "lstm_accuracy = accuracy_score(y_test_dl_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_dl_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# Calculate confidence scores for LSTM\n",
    "lstm_confidence_scores = lstm_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for LSTM\n",
    "lstm_trust_accuracy = trust_based_accuracy(y_test_dl_labels, lstm_y_pred_labels, lstm_confidence_scores, confidence_threshold)\n",
    "if lstm_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for LSTM: {lstm_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for LSTM\")\n",
    "\n",
    "# Define and train BiLSTM model\n",
    "bilstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_dl)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "bilstm_accuracy = accuracy_score(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Calculate confidence scores for BiLSTM\n",
    "bilstm_confidence_scores = bilstm_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for BiLSTM\n",
    "bilstm_trust_accuracy = trust_based_accuracy(y_test_dl_labels, bilstm_y_pred_labels, bilstm_confidence_scores, confidence_threshold)\n",
    "if bilstm_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for BiLSTM: {bilstm_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for BiLSTM\")\n",
    "\n",
    "# Compare all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': accuracy_score(y_test_ml, models['Naive Bayes'].predict(X_test_ml)),\n",
    "    'SVM': accuracy_score(y_test_ml, models['SVM'].predict(X_test_ml)),\n",
    "    'Random Forest': accuracy_score(y_test_ml, models['Random Forest'].predict(X_test_ml)),\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n",
    "\n",
    "trust_accuracy_scores_all = {\n",
    "    'Naive Bayes': trust_based_accuracy(y_test_ml, models['Naive Bayes'].predict(X_test_ml), models['Naive Bayes'].predict_proba(X_test_ml).max(axis=1), confidence_threshold),\n",
    "    'SVM': trust_based_accuracy(y_test_ml, models['SVM'].predict(X_test_ml), models['SVM'].predict_proba(X_test_ml).max(axis=1), confidence_threshold),\n",
    "    'Random Forest': trust_based_accuracy(y_test_ml, models['Random Forest'].predict(X_test_ml), models['Random Forest'].predict_proba(X_test_ml).max(axis=1), confidence_threshold),\n",
    "    'CNN': cnn_trust_accuracy,\n",
    "    'LSTM': lstm_trust_accuracy,\n",
    "    'BiLSTM': bilstm_trust_accuracy\n",
    "}\n",
    "\n",
    "best_trust_model = max(trust_accuracy_scores_all, key=lambda k: trust_accuracy_scores_all[k] if trust_accuracy_scores_all[k] is not None else -1)\n",
    "print(f\"\\nThe best model based on trust-based accuracy is: {best_trust_model} with trust-based accuracy {trust_accuracy_scores_all[best_trust_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "Supportive    4162\n",
      "Opposed        469\n",
      "Neutral        282\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.9187349879903923\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      0.98      0.97       826\n",
      "     Opposed       0.84      0.97      0.90       816\n",
      "  Supportive       0.97      0.82      0.89       856\n",
      "\n",
      "    accuracy                           0.92      2498\n",
      "   macro avg       0.92      0.92      0.92      2498\n",
      "weighted avg       0.93      0.92      0.92      2498\n",
      "\n",
      "Trust-Based Accuracy for Naive Bayes: 0.998661311914324\n",
      "SVM Results:\n",
      "Accuracy: 0.9655724579663731\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.96      1.00      0.98       826\n",
      "     Opposed       0.94      1.00      0.97       816\n",
      "  Supportive       1.00      0.90      0.95       856\n",
      "\n",
      "    accuracy                           0.97      2498\n",
      "   macro avg       0.97      0.97      0.97      2498\n",
      "weighted avg       0.97      0.97      0.97      2498\n",
      "\n",
      "Trust-Based Accuracy for SVM: 0.9787581699346405\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9795836669335468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       1.00      1.00      1.00       826\n",
      "     Opposed       0.97      0.97      0.97       816\n",
      "  Supportive       0.97      0.97      0.97       856\n",
      "\n",
      "    accuracy                           0.98      2498\n",
      "   macro avg       0.98      0.98      0.98      2498\n",
      "weighted avg       0.98      0.98      0.98      2498\n",
      "\n",
      "Trust-Based Accuracy for Random Forest: 1.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 3s - 52ms/step - accuracy: 0.8494 - loss: 0.5262 - val_accuracy: 0.8383 - val_loss: 0.4330\n",
      "Epoch 2/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.8567 - loss: 0.3460 - val_accuracy: 0.8515 - val_loss: 0.3579\n",
      "Epoch 3/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.9336 - loss: 0.2111 - val_accuracy: 0.8606 - val_loss: 0.4053\n",
      "Epoch 4/5\n",
      "62/62 - 2s - 28ms/step - accuracy: 0.9784 - loss: 0.0793 - val_accuracy: 0.8616 - val_loss: 0.4791\n",
      "Epoch 5/5\n",
      "62/62 - 2s - 27ms/step - accuracy: 0.9964 - loss: 0.0199 - val_accuracy: 0.8637 - val_loss: 0.5578\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8636826042726348\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.35      0.42        57\n",
      "           1       0.56      0.33      0.42       102\n",
      "           2       0.90      0.96      0.93       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.66      0.55      0.59       983\n",
      "weighted avg       0.84      0.86      0.85       983\n",
      "\n",
      "Trust-Based Accuracy for CNN: 0.9080717488789237\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 7s - 120ms/step - accuracy: 0.8405 - loss: 0.5864 - val_accuracy: 0.8383 - val_loss: 0.5198\n",
      "Epoch 2/5\n",
      "62/62 - 5s - 77ms/step - accuracy: 0.8501 - loss: 0.4510 - val_accuracy: 0.8423 - val_loss: 0.4230\n",
      "Epoch 3/5\n",
      "62/62 - 5s - 80ms/step - accuracy: 0.8753 - loss: 0.3166 - val_accuracy: 0.8535 - val_loss: 0.3836\n",
      "Epoch 4/5\n",
      "62/62 - 5s - 75ms/step - accuracy: 0.9265 - loss: 0.2141 - val_accuracy: 0.8566 - val_loss: 0.4821\n",
      "Epoch 5/5\n",
      "62/62 - 5s - 75ms/step - accuracy: 0.9458 - loss: 0.1518 - val_accuracy: 0.8555 - val_loss: 0.4522\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8555442522889115\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.33      0.39        57\n",
      "           1       0.53      0.28      0.37       102\n",
      "           2       0.89      0.96      0.93       824\n",
      "\n",
      "    accuracy                           0.86       983\n",
      "   macro avg       0.63      0.53      0.56       983\n",
      "weighted avg       0.83      0.86      0.84       983\n",
      "\n",
      "Trust-Based Accuracy for LSTM: 0.9152744630071599\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 12s - 193ms/step - accuracy: 0.8394 - loss: 0.5527 - val_accuracy: 0.8393 - val_loss: 0.5067\n",
      "Epoch 2/5\n",
      "62/62 - 7s - 120ms/step - accuracy: 0.8529 - loss: 0.3914 - val_accuracy: 0.8474 - val_loss: 0.4270\n",
      "Epoch 3/5\n",
      "62/62 - 7s - 111ms/step - accuracy: 0.8885 - loss: 0.2749 - val_accuracy: 0.8606 - val_loss: 0.3841\n",
      "Epoch 4/5\n",
      "62/62 - 7s - 117ms/step - accuracy: 0.9198 - loss: 0.2037 - val_accuracy: 0.8616 - val_loss: 0.4488\n",
      "Epoch 5/5\n",
      "62/62 - 8s - 128ms/step - accuracy: 0.9481 - loss: 0.1465 - val_accuracy: 0.8545 - val_loss: 0.4815\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.854526958290946\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.30      0.41        57\n",
      "           1       0.46      0.36      0.41       102\n",
      "           2       0.90      0.95      0.92       824\n",
      "\n",
      "    accuracy                           0.85       983\n",
      "   macro avg       0.68      0.54      0.58       983\n",
      "weighted avg       0.84      0.85      0.84       983\n",
      "\n",
      "Trust-Based Accuracy for BiLSTM: 0.9085510688836105\n",
      "Topic 1:\n",
      "card work great phone memory gb good price fast sd\n",
      "Topic 2:\n",
      "card sandisk gopro work use phone memory great hero camera\n",
      "Topic 3:\n",
      "nvidia shield lapse nail member vids retailer advise missing yep\n",
      "Topic 4:\n",
      "rom blah sturdy yoga throughput portable scanner survive recomended wonderful\n",
      "Topic 5:\n",
      "fair designed pi raspberry met film recomend excelent handling leader\n",
      "   reviewerName  \\\n",
      "1          0mie   \n",
      "2           1K3   \n",
      "3           1m2   \n",
      "4  2&amp;1/2Men   \n",
      "5       2Cents!   \n",
      "\n",
      "                                                                                                                                                                                                                  reviewText  \\\n",
      "1                                                                                                                                purchased device worked advertised never much phone memory since download lot stuff brainer   \n",
      "2                                                                                                                              work expected sprung higher capacity think made bit cheesier earlier version paint look clean   \n",
      "3                                            think worked greathad diff bran gb card went south monthsthis one held pretty well since note update ive month zero issue since transferred note note card reliable solidcheers   \n",
      "4  bought retail packaging arrived legit orange envelope english version asian like picture show arrived quickly bought retail packaging htc one sv lg optimus card working order probably best price youll get nice sd card   \n",
      "5                                                          mini storage doesnt anything else supposed purchased add additional storage microsoft surface pro tablet come gb supposed sandisk long standing reputation speaks   \n",
      "\n",
      "       Stance  Topic  \n",
      "1  Supportive      0  \n",
      "2  Supportive      1  \n",
      "3     Neutral      0  \n",
      "4  Supportive      0  \n",
      "5     Opposed      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "from googletrans import Translator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Load NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load the original dataset\n",
    "df_original = pd.read_csv('5kReviewWithSentimentAmazon.csv')\n",
    "\n",
    "# Keep 'reviewerName', 'reviewText', and 'Stance' columns\n",
    "df = df_original[['reviewerName', 'reviewText', 'Stance']]\n",
    "\n",
    "# Drop rows where any of the required columns are NaN\n",
    "df = df.dropna(subset=['reviewerName', 'reviewText', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'reviewText' are strings\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "\n",
    "# For full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])  # Lemmatize and remove stopwords\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Define back-translation function\n",
    "def back_translate(text, src_language='en', mid_language='fr'):\n",
    "    try:\n",
    "        translated_text = translator.translate(text, src=src_language, dest=mid_language).text\n",
    "        back_translated_text = translator.translate(translated_text, src=mid_language, dest=src_language).text\n",
    "        return back_translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during back-translation: {e}\")\n",
    "        return text\n",
    "\n",
    "# Define function to augment minority class\n",
    "def augment_minority_class(df, class_label, src_language='en', mid_language='fr'):\n",
    "    minority_texts = df[df['Stance'] == class_label]['reviewText'].tolist()\n",
    "    augmented_texts = [back_translate(text, src_language, mid_language) for text in minority_texts]\n",
    "    augmented_labels = [class_label] * len(augmented_texts)\n",
    "    return pd.DataFrame({'reviewText': augmented_texts, 'Stance': augmented_labels})\n",
    "\n",
    "# Define threshold for minority class\n",
    "threshold = 100  # Adjust based on your needs\n",
    "\n",
    "# Identify minority classes\n",
    "class_counts = df['Stance'].value_counts()\n",
    "minority_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "\n",
    "# Apply back-translation for all minority classes\n",
    "augmented_df_list = [augment_minority_class(df, cls) for cls in minority_classes]\n",
    "df_augmented = pd.concat([df] + augmented_df_list, ignore_index=True)\n",
    "\n",
    "# Text Vectorization for ML models\n",
    "tfidf = TfidfVectorizer(max_df=0.7)\n",
    "X = tfidf.fit_transform(df_augmented['reviewText'])\n",
    "y = df_augmented['Stance']\n",
    "\n",
    "# Handle class imbalance using SMOTE for traditional ML models\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Split dataset for ML models\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate ML models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(kernel='linear', probability=True),  # Set probability=True for SVM\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Confidence threshold\n",
    "confidence_threshold = 0.8\n",
    "\n",
    "def trust_based_accuracy(y_true, y_pred, confidence_scores, threshold):\n",
    "    mask = confidence_scores >= threshold\n",
    "    y_true_trust = y_true[mask]\n",
    "    y_pred_trust = y_pred[mask]\n",
    "    if len(y_true_trust) == 0:\n",
    "        return None  # No predictions above the threshold\n",
    "    return accuracy_score(y_true_trust, y_pred_trust)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_ml, y_train_ml)\n",
    "    y_pred = model.predict(X_test_ml)\n",
    "    y_probs = model.predict_proba(X_test_ml)\n",
    "    confidence_scores = y_probs.max(axis=1)\n",
    "    \n",
    "    # Calculate standard accuracy\n",
    "    accuracy = accuracy_score(y_test_ml, y_pred)\n",
    "    report = classification_report(y_test_ml, y_pred)\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Calculate trust-based accuracy\n",
    "    trust_accuracy = trust_based_accuracy(y_test_ml, y_pred, confidence_scores, confidence_threshold)\n",
    "    if trust_accuracy is not None:\n",
    "        print(f\"Trust-Based Accuracy for {name}: {trust_accuracy}\")\n",
    "    else:\n",
    "        print(f\"No predictions above the confidence threshold for {name}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_augmented['reviewText'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_augmented['reviewText'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "y_encoded = pd.get_dummies(df_augmented['Stance']).values\n",
    "\n",
    "# Split dataset for deep learning models\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train CNN model\n",
    "cnn_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test_dl)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_dl_labels = y_test_dl.argmax(axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_dl_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_dl_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# Calculate confidence scores for CNN\n",
    "cnn_confidence_scores = cnn_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for CNN\n",
    "cnn_trust_accuracy = trust_based_accuracy(y_test_dl_labels, cnn_y_pred_labels, cnn_confidence_scores, confidence_threshold)\n",
    "if cnn_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for CNN: {cnn_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for CNN\")\n",
    "\n",
    "# Define and train LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test_dl)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "lstm_accuracy = accuracy_score(y_test_dl_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_dl_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# Calculate confidence scores for LSTM\n",
    "lstm_confidence_scores = lstm_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for LSTM\n",
    "lstm_trust_accuracy = trust_based_accuracy(y_test_dl_labels, lstm_y_pred_labels, lstm_confidence_scores, confidence_threshold)\n",
    "if lstm_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for LSTM: {lstm_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for LSTM\")\n",
    "\n",
    "# Define and train BiLSTM model\n",
    "bilstm_model = Sequential([\n",
    "    Embedding(5000, 128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test_dl)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "bilstm_accuracy = accuracy_score(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_dl_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Calculate confidence scores for BiLSTM\n",
    "bilstm_confidence_scores = bilstm_y_pred.max(axis=1)\n",
    "\n",
    "# Calculate trust-based accuracy for BiLSTM\n",
    "bilstm_trust_accuracy = trust_based_accuracy(y_test_dl_labels, bilstm_y_pred_labels, bilstm_confidence_scores, confidence_threshold)\n",
    "if bilstm_trust_accuracy is not None:\n",
    "    print(f\"Trust-Based Accuracy for BiLSTM: {bilstm_trust_accuracy}\")\n",
    "else:\n",
    "    print(f\"No predictions above the confidence threshold for BiLSTM\")\n",
    "\n",
    "# # Topic Modeling with LDA\n",
    "# # Vectorize the text data using TF-IDF for topic modeling\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.7, stop_words='english')\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(df['reviewText'])\n",
    "\n",
    "# # Number of topics\n",
    "# num_topics = 5\n",
    "\n",
    "# # Define the LDA model\n",
    "# lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "\n",
    "# # Fit the LDA model\n",
    "# lda.fit(tfidf_matrix)\n",
    "\n",
    "# # Get the topics\n",
    "# def display_topics(model, feature_names, num_top_words):\n",
    "#     for topic_idx, topic in enumerate(model.components_):\n",
    "#         print(f\"Topic {topic_idx + 1}:\")\n",
    "#         print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n",
    "\n",
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "# display_topics(lda, tfidf_feature_names, 10)\n",
    "\n",
    "# # Assign topic labels to each review\n",
    "# topic_assignments = lda.transform(tfidf_matrix)\n",
    "# df['Topic'] = topic_assignments.argmax(axis=1)\n",
    "\n",
    "# # Print the first few rows to see the assigned topics\n",
    "# print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
