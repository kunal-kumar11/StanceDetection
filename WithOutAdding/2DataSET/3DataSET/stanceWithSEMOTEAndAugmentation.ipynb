{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\python312\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\moneykicks\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow imbalanced-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moneykicks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance\n",
      "neutral       10234\n",
      "supportive    10234\n",
      "oppose        10234\n",
      "Name: count, dtype: int64\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.7637192639635239\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.81      0.64      0.71      2076\n",
      "      oppose       0.72      0.79      0.76      2038\n",
      "  supportive       0.77      0.86      0.81      2027\n",
      "\n",
      "    accuracy                           0.76      6141\n",
      "   macro avg       0.77      0.76      0.76      6141\n",
      "weighted avg       0.77      0.76      0.76      6141\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.7726754600227976\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.74      0.75      0.74      2076\n",
      "      oppose       0.78      0.73      0.75      2038\n",
      "  supportive       0.80      0.84      0.82      2027\n",
      "\n",
      "    accuracy                           0.77      6141\n",
      "   macro avg       0.77      0.77      0.77      6141\n",
      "weighted avg       0.77      0.77      0.77      6141\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.7873310535743364\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.78      0.75      0.77      2076\n",
      "      oppose       0.78      0.74      0.76      2038\n",
      "  supportive       0.80      0.87      0.83      2027\n",
      "\n",
      "    accuracy                           0.79      6141\n",
      "   macro avg       0.79      0.79      0.79      6141\n",
      "weighted avg       0.79      0.79      0.79      6141\n",
      "\n",
      "\n",
      "The best model based on accuracy is: Random Forest with accuracy 0.7873310535743364\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/695 - 16s - 23ms/step - accuracy: 0.8180 - loss: 0.4602 - val_accuracy: 0.8494 - val_loss: 0.3940\n",
      "Epoch 2/5\n",
      "695/695 - 15s - 21ms/step - accuracy: 0.8800 - loss: 0.3202 - val_accuracy: 0.8545 - val_loss: 0.3755\n",
      "Epoch 3/5\n",
      "695/695 - 15s - 21ms/step - accuracy: 0.9118 - loss: 0.2462 - val_accuracy: 0.8589 - val_loss: 0.3814\n",
      "Epoch 4/5\n",
      "695/695 - 15s - 22ms/step - accuracy: 0.9328 - loss: 0.1939 - val_accuracy: 0.8611 - val_loss: 0.3997\n",
      "Epoch 5/5\n",
      "695/695 - 15s - 21ms/step - accuracy: 0.9455 - loss: 0.1597 - val_accuracy: 0.8584 - val_loss: 0.4327\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "CNN Results:\n",
      "Accuracy: 0.8583513318934485\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      3486\n",
      "           1       0.87      0.87      0.87      4016\n",
      "           2       0.88      0.93      0.90      3610\n",
      "\n",
      "    accuracy                           0.86     11112\n",
      "   macro avg       0.86      0.86      0.86     11112\n",
      "weighted avg       0.86      0.86      0.86     11112\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/695 - 45s - 65ms/step - accuracy: 0.7941 - loss: 0.5136 - val_accuracy: 0.8419 - val_loss: 0.4138\n",
      "Epoch 2/5\n",
      "695/695 - 47s - 67ms/step - accuracy: 0.8612 - loss: 0.3681 - val_accuracy: 0.8569 - val_loss: 0.3730\n",
      "Epoch 3/5\n",
      "695/695 - 46s - 66ms/step - accuracy: 0.8761 - loss: 0.3311 - val_accuracy: 0.8616 - val_loss: 0.3590\n",
      "Epoch 4/5\n",
      "695/695 - 45s - 65ms/step - accuracy: 0.8863 - loss: 0.3051 - val_accuracy: 0.8625 - val_loss: 0.3531\n",
      "Epoch 5/5\n",
      "695/695 - 46s - 66ms/step - accuracy: 0.8950 - loss: 0.2851 - val_accuracy: 0.8663 - val_loss: 0.3528\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
      "LSTM Results:\n",
      "Accuracy: 0.8662706983441325\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      3486\n",
      "           1       0.87      0.90      0.89      4016\n",
      "           2       0.91      0.91      0.91      3610\n",
      "\n",
      "    accuracy                           0.87     11112\n",
      "   macro avg       0.86      0.86      0.86     11112\n",
      "weighted avg       0.87      0.87      0.87     11112\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/695 - 74s - 107ms/step - accuracy: 0.7905 - loss: 0.5154 - val_accuracy: 0.8403 - val_loss: 0.4095\n",
      "Epoch 2/5\n",
      "695/695 - 68s - 97ms/step - accuracy: 0.8600 - loss: 0.3690 - val_accuracy: 0.8539 - val_loss: 0.3808\n",
      "Epoch 3/5\n",
      "695/695 - 68s - 97ms/step - accuracy: 0.8783 - loss: 0.3296 - val_accuracy: 0.8633 - val_loss: 0.3607\n",
      "Epoch 4/5\n",
      "695/695 - 68s - 98ms/step - accuracy: 0.8861 - loss: 0.3075 - val_accuracy: 0.8629 - val_loss: 0.3558\n",
      "Epoch 5/5\n",
      "695/695 - 68s - 98ms/step - accuracy: 0.8947 - loss: 0.2876 - val_accuracy: 0.8687 - val_loss: 0.3496\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "BiLSTM Results:\n",
      "Accuracy: 0.8687005039596832\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      3486\n",
      "           1       0.89      0.88      0.88      4016\n",
      "           2       0.91      0.92      0.91      3610\n",
      "\n",
      "    accuracy                           0.87     11112\n",
      "   macro avg       0.87      0.87      0.87     11112\n",
      "weighted avg       0.87      0.87      0.87     11112\n",
      "\n",
      "\n",
      "The best model based on accuracy is: BiLSTM with accuracy 0.8687005039596832\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Dense, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "import numpy as np\n",
    "\n",
    "# Ensure NLTK stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('balanced_200kReviewWithSentimentFlipkart.csv')\n",
    "\n",
    "# # Function to map sentiment to stance\n",
    "# def sentiment_to_stance(sentiment):\n",
    "#     if sentiment == 'positive':\n",
    "#         return 'supportive'\n",
    "#     elif sentiment == 'negative':\n",
    "#         return 'oppose'\n",
    "#     else:\n",
    "#         return 'neutral'\n",
    "# # Apply the function to create the stance column\n",
    "# df['Stance'] = df['Sentiment'].apply(sentiment_to_stance)\n",
    "# # Save the DataFrame to a new CSV file\n",
    "# df.to_csv('reviews_with_stance.csv', index=False)\n",
    "\n",
    "# Keep only 'Summary' and 'Stance' columns\n",
    "df = df[['Summary', 'Stance']]\n",
    "\n",
    "# Drop rows where 'Summary' or 'Stance' is NaN\n",
    "df = df.dropna(subset=['Summary', 'Stance'])\n",
    "\n",
    "# Ensure all entries in 'Summary' are strings\n",
    "df['Summary'] = df['Summary'].astype(str)\n",
    "\n",
    "# for full review display without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print value counts of 'Stance' column\n",
    "print(df['Stance'].value_counts())\n",
    "\n",
    "# Preprocess the text data\n",
    "stop_words = list(stopwords.words('english'))\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, max_df=0.7)\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "X = tfidf.fit_transform(df['Summary'])\n",
    "\n",
    "# Encode the target labels\n",
    "y = df['Stance']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the stances on the test set using Naive Bayes\n",
    "nb_y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "nb_report = classification_report(y_test, nb_y_pred)\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the stances on the test set using SVM\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "svm_report = classification_report(y_test, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the stances on the test set using Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_report = classification_report(y_test, rf_y_pred)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "# Initialize the accuracy_scores dictionary\n",
    "accuracy_scores = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model based on accuracy\n",
    "best_model = max(accuracy_scores, key=accuracy_scores.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores[best_model]}\")\n",
    "\n",
    "# Tokenizer and padding for deep learning models\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['Summary'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['Summary'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for deep learning models\n",
    "y_encoded = pd.get_dummies(df['Stance']).values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation for deep learning models\n",
    "def augment_text(text):\n",
    "    words = text_to_word_sequence(text)\n",
    "    augmented_texts = [text]\n",
    "    if len(words) > 1:\n",
    "        augmented_texts.append(' '.join(np.random.permutation(words)))\n",
    "    return augmented_texts\n",
    "\n",
    "augmented_summaries = []\n",
    "augmented_stances = []\n",
    "\n",
    "for summary, stance in zip(df['Summary'], df['Stance']):\n",
    "    augmented_texts = augment_text(summary)\n",
    "    for text in augmented_texts:\n",
    "        augmented_summaries.append(text)\n",
    "        augmented_stances.append(stance)\n",
    "\n",
    "# Tokenizer and padding for augmented data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(augmented_summaries)\n",
    "X_aug_seq = tokenizer.texts_to_sequences(augmented_summaries)\n",
    "X_aug_pad = pad_sequences(X_aug_seq, maxlen=100)\n",
    "\n",
    "# Encode the target labels for augmented data\n",
    "y_aug_encoded = pd.get_dummies(augmented_stances).values\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_aug_pad, y_aug_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(5000, 128, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "cnn_y_pred = cnn_model.predict(X_test)\n",
    "cnn_y_pred_labels = cnn_y_pred.argmax(axis=1)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test_labels, cnn_y_pred_labels)\n",
    "cnn_report = classification_report(y_test_labels, cnn_y_pred_labels)\n",
    "print(\"CNN Results:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(cnn_report)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "lstm_y_pred = lstm_model.predict(X_test)\n",
    "lstm_y_pred_labels = lstm_y_pred.argmax(axis=1)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test_labels, lstm_y_pred_labels)\n",
    "lstm_report = classification_report(y_test_labels, lstm_y_pred_labels)\n",
    "print(\"LSTM Results:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(lstm_report)\n",
    "\n",
    "# BiLSTM Model\n",
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(5000, 128, input_length=100))\n",
    "bilstm_model.add(SpatialDropout1D(0.2))\n",
    "bilstm_model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "bilstm_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "bilstm_y_pred = bilstm_model.predict(X_test)\n",
    "bilstm_y_pred_labels = bilstm_y_pred.argmax(axis=1)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "\n",
    "bilstm_accuracy = accuracy_score(y_test_labels, bilstm_y_pred_labels)\n",
    "bilstm_report = classification_report(y_test_labels, bilstm_y_pred_labels)\n",
    "print(\"BiLSTM Results:\")\n",
    "print(f\"Accuracy: {bilstm_accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(bilstm_report)\n",
    "\n",
    "# Compare the accuracy of all models\n",
    "accuracy_scores_all = {\n",
    "    'Naive Bayes': nb_accuracy,\n",
    "    'SVM': svm_accuracy,\n",
    "    'Random Forest': rf_accuracy,\n",
    "    'CNN': cnn_accuracy,\n",
    "    'LSTM': lstm_accuracy,\n",
    "    'BiLSTM': bilstm_accuracy\n",
    "}\n",
    "\n",
    "# Find the best model among all based on accuracy\n",
    "best_model = max(accuracy_scores_all, key=accuracy_scores_all.get)\n",
    "print(f\"\\nThe best model based on accuracy is: {best_model} with accuracy {accuracy_scores_all[best_model]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
